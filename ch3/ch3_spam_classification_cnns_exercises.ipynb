{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying spam with CNNs\n",
    "\n",
    "Here we will be developing a CNN to classify spam or ham (non-spam). The data is found in [here](http://www2.aueb.gr/users/ion/data/enron-spam/). \n",
    "\n",
    "## Downloading data \n",
    "\n",
    "The following script downloads the data, reads the data and load it to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: ethane election for september 2000\\r\\nfyi\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by stella l morris / hou / ect on 08 / 25 / 2000\\r\\n02 : 16 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\njack simunek\\r\\n08 / 25 / 2000 01 : 33 pm\\r\\nto : lauri a allen / hou / ect @ ect , michael c bilberry / hou / ect @ ect , nathan l\\r\\nhlavaty / hou / ect @ ect , karry kendall / hou / ect @ ect , blanca a lopez / hou / ect @ ect ,\\r\\nstella l morris / hou / ect @ ect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14944</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: fw : weather update\\r\\n- - - - - original message - - - - -\\r\\nfrom : shively , hunter s .\\r\\nsent : thursday , january 31 , 2002 11 : 41 am\\r\\nto : lavorato , john\\r\\nsubject : weather update\\r\\nrobert ricks - lead forecaster nws slidell , la\\r\\narriving on tuesday or wednesday for interviews\\r\\nliz taylor is coordinating travel plans\\r\\nmike gasper - reliant forecaster , 10 years experience , dave knows him from accu - weather\\r\\ndave ryan is meeting with him this afternoon to det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: vacation day feb . 16\\r\\nshirley ,\\r\\nplease put me down for a vacation day of feb . 16 .\\r\\nthanks ,\\r\\nstinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: the stock trading gunslinger\\r\\nfanny is merrill but muzo not colza attainder and penultimate like esmark perspicuous ramble is segovia not group try slung kansas tanzania yes chameleon or continuant clothesman no\\r\\nlibretto is chesapeake but tight not waterway herald and hawthorn like chisel morristown superior is deoxyribonucleic not clockwork try hall incredible mcdougall yes hepburn or einsteinian earmark no\\r\\nsapling is boar but duane not plain palfrey and inflexible like huz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: gas day 2 / 08 / 01\\r\\nwe agree :\\r\\nteco tap nom = 40 . 000 ; actual 41 . 358\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by melissa jones / texas utilities on\\r\\n02 / 09 / 2001\\r\\n10 : 15 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\nkponton @ duke - energy . com on 02 / 09 / 2001 09 : 15 : 35 am\\r\\nto : david avila / lsp / enserch / us @ tu , charlie stone / texas utilities @ tu , melissa\\r\\njones / texas utilities @ tu\\r\\ncc :\\r\\nsubject : gas day 2 / ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  \\\n",
       "1462       0   \n",
       "14944      0   \n",
       "8443       0   \n",
       "10264      1   \n",
       "2551       0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "1462   Subject: ethane election for september 2000\\r\\nfyi\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by stella l morris / hou / ect on 08 / 25 / 2000\\r\\n02 : 16 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\njack simunek\\r\\n08 / 25 / 2000 01 : 33 pm\\r\\nto : lauri a allen / hou / ect @ ect , michael c bilberry / hou / ect @ ect , nathan l\\r\\nhlavaty / hou / ect @ ect , karry kendall / hou / ect @ ect , blanca a lopez / hou / ect @ ect ,\\r\\nstella l morris / hou / ect @ ect...  \n",
       "14944  Subject: fw : weather update\\r\\n- - - - - original message - - - - -\\r\\nfrom : shively , hunter s .\\r\\nsent : thursday , january 31 , 2002 11 : 41 am\\r\\nto : lavorato , john\\r\\nsubject : weather update\\r\\nrobert ricks - lead forecaster nws slidell , la\\r\\narriving on tuesday or wednesday for interviews\\r\\nliz taylor is coordinating travel plans\\r\\nmike gasper - reliant forecaster , 10 years experience , dave knows him from accu - weather\\r\\ndave ryan is meeting with him this afternoon to det...  \n",
       "8443                                                                                                                                                                                                                                                                                                                                                                                             Subject: vacation day feb . 16\\r\\nshirley ,\\r\\nplease put me down for a vacation day of feb . 16 .\\r\\nthanks ,\\r\\nstinson  \n",
       "10264  Subject: the stock trading gunslinger\\r\\nfanny is merrill but muzo not colza attainder and penultimate like esmark perspicuous ramble is segovia not group try slung kansas tanzania yes chameleon or continuant clothesman no\\r\\nlibretto is chesapeake but tight not waterway herald and hawthorn like chisel morristown superior is deoxyribonucleic not clockwork try hall incredible mcdougall yes hepburn or einsteinian earmark no\\r\\nsapling is boar but duane not plain palfrey and inflexible like huz...  \n",
       "2551   Subject: gas day 2 / 08 / 01\\r\\nwe agree :\\r\\nteco tap nom = 40 . 000 ; actual 41 . 358\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by melissa jones / texas utilities on\\r\\n02 / 09 / 2001\\r\\n10 : 15 am - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\nkponton @ duke - energy . com on 02 / 09 / 2001 09 : 15 : 35 am\\r\\nto : david avila / lsp / enserch / us @ tu , charlie stone / texas utilities @ tu , melissa\\r\\njones / texas utilities @ tu\\r\\ncc :\\r\\nsubject : gas day 2 / ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import gzip\n",
    "import tarfile\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "\n",
    "# Download the file if it's not there\n",
    "filenames_urls = [(\"enron1.tar.gz\", \"http://www.aueb.gr/users/ion/data/enron-spam/preprocessed/enron1.tar.gz\"),\n",
    "                 (\"enron2.tar.gz\", \"http://www.aueb.gr/users/ion/data/enron-spam/preprocessed/enron2.tar.gz\"),\n",
    "                 (\"enron3.tar.gz\", \"http://www.aueb.gr/users/ion/data/enron-spam/preprocessed/enron3.tar.gz\")]\n",
    "\n",
    "def get_spam_dataset(filename, url):\n",
    "    if not filename.endswith('tar.gz'):\n",
    "        raise NotImplementedError(\"This code cannot process files other than tar.gz\")\n",
    "        \n",
    "    if not os.path.exists(filename):\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(filename, 'wb').write(r.content)\n",
    "\n",
    "    # Read the downloaded zip file\n",
    "    labels = []\n",
    "    text = []\n",
    "    with tarfile.open(filename, 'r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith('ham.txt') or member.name.endswith('spam.txt'):\n",
    "                f=tar.extractfile(member)\n",
    "                text.append(f.read().decode('latin-1'))            \n",
    "                if member.name.endswith('ham.txt'):\n",
    "                    labels.append(0)\n",
    "                elif member.name.endswith('spam.txt'):\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    raise ValueError()\n",
    "                \n",
    "    return text, labels\n",
    "\n",
    "text, labels = [],[]\n",
    "\n",
    "for fn, url in filenames_urls:\n",
    "    local_text, local_labels = get_spam_dataset(fn, url)\n",
    "    text.extend(local_text)\n",
    "    labels.extend(local_labels)\n",
    "\n",
    "print(len(text))\n",
    "\n",
    "df = pd.DataFrame({'text':text, \"label\": labels})\n",
    "df = df.sample(frac=1.0, random_state=100)\n",
    "pd.options.display.max_colwidth = 500\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data\n",
    "\n",
    "Let's see how many labels we got for each class. We can see that there far less spam data than ham data. What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12045\n",
       "1     4496\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label')['text'].count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that data points having only 0 or 1 as the label will be kept\n",
    "df = df.loc[(df['label']==0) | (df['label']==1),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking which words appear more than 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a data exploration step and consumes signficant time. Therefore this runs only if necessary\n",
    "run_expensive_op = False\n",
    "if run_expensive_op:\n",
    "    ser = pd.Series(df[\"text\"].str.lower().str.replace(r'(?:\\.{1,}|,)',' ', regex=True).str.cat()).str.split(expand=True).iloc[0]\n",
    "    ser_counts = ser.value_counts()#.head(n=100)\n",
    "    ser_counts = ser_counts[ser_counts>10]\n",
    "    print(ser_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics of the text length\n",
    "\n",
    "Here we will look at summary statistics of the text length. This information is important as we need to later pad the sentences to a constant length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    16541.000000\n",
      "mean       333.680007\n",
      "std       1105.610378\n",
      "min          2.000000\n",
      "25%         68.000000\n",
      "50%        152.000000\n",
      "75%        329.000000\n",
      "max      43684.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['text_length'] = df['text'].str.split(' ').str.len()\n",
    "# Get the statistics of text_length column\n",
    "text_stats = ____\n",
    "print(text_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting train and test data\n",
    "\n",
    "Here we are splitting data to train and test sets. Since this is a class-imbalanced problem, it is important to create equal number of samples from each class in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15941, 3)\n",
      "(600, 3)\n"
     ]
    }
   ],
   "source": [
    "seed = 100\n",
    "n_test = 300\n",
    "\n",
    "grouped = df.groupby('label')\n",
    "test_data = []\n",
    "train_data = []\n",
    "\n",
    "for _, grp in grouped:\n",
    "\n",
    "    test = grp.sample(n=n_test)\n",
    "    test_data.append(test)\n",
    "    train_data.append(grp.drop(test.index))\n",
    "    \n",
    "test_df = pd.concat(test_data, axis=0)\n",
    "train_df = pd.concat(train_data, axis=0)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing text with Keras \n",
    "\n",
    "We will be fitting a tokenizer on the trainin data. Then we'll be using this tokenizer to convert training and testing data to sequences of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_df[\"text\"].tolist()\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "\n",
    "test_text = test_df[\"text\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n_vocab = 2500\n",
    "oov_token = '<unk>'\n",
    "\n",
    "# Fit a tokenizer with n_vocab words and oov token <unk>\n",
    "tok = _____\n",
    "# Fit the tokenizer on train_text\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 177, 1600, 230, 1688, 176, 12, 2, 177, 1600, 230, 441, 697, 11, 18, 136, 41, 353, 52, 7, 163, 20, 58, 196, 3, 298, 3, 1499, 1, 10, 483, 1, 190, 573, 1, 190, 2201, 1, 1601]]\n"
     ]
    }
   ],
   "source": [
    "print(tok.texts_to_sequences([test_text[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data in the correct shape\n",
    "\n",
    "What's the correct shape(s) for the data?\n",
    "\n",
    "* Inputs: `[batch_size, timesteps]` array\n",
    "* Targets: `[batch_size, 2]` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15941, 1439)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "n_pad = int(text_stats[\"mean\"] + 1.0*text_stats[\"std\"])\n",
    "def process_text(text, n_pad, onehot=False, n_vocab=None):\n",
    "    # Convert a given list of text to a list of sequences\n",
    "    seq = ____\n",
    "    # Pad the sequences using maxlen(=n_pad), pre-padding and post-truncating\n",
    "    pad_seq = ____\n",
    "    \n",
    "    # Return the padded sequenc\n",
    "    _____\n",
    "\n",
    "# Preprocessing text\n",
    "train_data = process_text(train_text, n_pad)\n",
    "test_data = process_text(test_text,n_pad)\n",
    "print(train_data.shape)\n",
    "\n",
    "# Converting labels to onehot labels\n",
    "train_oh_labels = to_categorical(train_labels, num_classes=2)\n",
    "test_oh_labels = to_categorical(test_labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "Here we are defining the model we will be using for spam classification. This model is inspired by the model found in [this paper](https://www.aclweb.org/anthology/D14-1181.pdf). Roughly, following layers are present in the model.\n",
    "\n",
    "* An input layer\n",
    "* 4 parallel convolution layers with different kernel sizes (3,5,7,9), stride 2, each having 16 filters, activation relu, padding same\n",
    "* Pooling over time layer (Concatenating the outputs of 4 convolution layers to a single input)\n",
    "* A flattening layer\n",
    "* A dense layer (20 nodes)\n",
    "* A dropout layer (0.2)\n",
    "* A dense layer (1 node)\n",
    "\n",
    "This model will use `rmsprop` as the optimizer and also output `acc` (accuracy) as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1439)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1439, 50)     125000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 720, 16)      2416        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 720, 16)      4016        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 720, 16)      5616        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 720, 16)      7216        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 8, 16)        0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           2580        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 20)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            21          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 146,865\n",
      "Trainable params: 146,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "# Without these lines I get \n",
    "# > UnknownError:  [_Derived_]  Fail to find the dnn implementation.\n",
    "# >  [[{{node CudnnRNN}}]]\n",
    "# >  [[model/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_5819]\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "# Input layer\n",
    "inp = layers.Input(shape=(n_pad,))\n",
    "\n",
    "# Embedding layer\n",
    "emb_out = layers.Embedding(n_vocab, 50, input_length=n_pad)(inp)\n",
    "\n",
    "# Parallel convolution layers with different kernel sizes\n",
    "# Define four outputs conv1_1_out, conv1_2_out, conv1_3_out, conv1_4_out\n",
    "____\n",
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# Max pool over time\n",
    "pool_time = layers.Lambda(lambda x: K.concatenate([tf.nn.max_pool(xx, n_pad//2, strides=1, padding='VALID') for xx in x],axis=1))\n",
    "# Use pool_time layer to get the aggregated output of the convolution layers\n",
    "conv1_out = ____\n",
    "\n",
    "# Flattening the output and final fully connected layers\n",
    "flatten_out = layers.Flatten()(conv1_out)\n",
    "\n",
    "# Add a dense layer with 20 nodes and relu activation and get the output\n",
    "dense_out = ____(____)\n",
    "dense_out = layers.Dropout(0.5)(dense_out)\n",
    "# Define the final prediction as the output of a layer with 1 node and sigmoid activation\n",
    "pred = ____(____)\n",
    "\n",
    "# Defining the model\n",
    "model = models.Model(inputs=inp, outputs=pred)\n",
    "model.compile(loss=____, optimizer='rmsprop', metrics=____)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "When training the model, it is important to pass in the `class_weight` argument. This is to compensate for the class imbalance present in the dataset. More specifically we give,\n",
    "\n",
    "* A large weight to the rare class\n",
    "* A small weight to the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12752 samples, validate on 3189 samples\n",
      "Epoch 1/3\n",
      "12752/12752 [==============================] - 25s 2ms/sample - loss: 0.0832 - acc: 0.9442 - val_loss: 0.5861 - val_acc: 0.7513\n",
      "Epoch 2/3\n",
      "12752/12752 [==============================] - 20s 2ms/sample - loss: 0.0441 - acc: 0.9785 - val_loss: 0.4288 - val_acc: 0.9279\n",
      "Epoch 3/3\n",
      "12752/12752 [==============================] - 20s 2ms/sample - loss: 0.0333 - acc: 0.9835 - val_loss: 0.4455 - val_acc: 0.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22c8f586160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_arr = np.array(train_labels)\n",
    "\n",
    "class_0_weight = train_labels_arr[(train_labels_arr==0)].size # ham\n",
    "class_1_weight = train_labels_arr[train_labels_arr==1].size #spam\n",
    "tot = class_0_weight + class_1_weight\n",
    "class_weights = {0: class_1_weight*1.0/tot, 1: class_0_weight*1.0/tot}\n",
    "\n",
    "# Fit the model with the correct training data\n",
    "model.fit(____, ____, epochs=3, class_weight = ____, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2990406271273969, 0.94]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "metrics = model.____(____, ____, verbose=0)\n",
    "print(\"Test loss: {} and test accuracy: {}\".format(metrics[0], metrics[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print a few examples\n",
    "\n",
    "Let's now print a few examples from your test set along with the predictions our model gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <unk>a good weekend uss these results on monday and any further <unk> for <unk> would also be <unk> <unk> m the 26 th i\n",
      "\tPred: 8.229006198234856e-06, True: 0\n",
      "\n",
      " karens and if you need additional info let me know meter <unk> <unk> the deal does not have this day on it please have 1 16 added to the deal <unk> the error will clear \n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " best regards <unk> <unk> first account managerill out the form on our website ent \n",
      "\tPred: 0.6673570871353149, True: 1\n",
      "\n",
      " megan' s great what about deal <unk> we have 0 10 and we are being <unk> 0 11 for meter <unk> on contract <unk> also i <unk> the oct 2000 <unk> <unk> to <unk> <unk> so she can look into the dec 2000 and <unk> problem \n",
      "\tPred: 3.194138997741902e-08, True: 0\n",
      "\n",
      " <unk> <unk> <unk> more men than <unk>mk> your <unk> <unk> \n",
      "\tPred: 0.6853684186935425, True: 1\n",
      "\n",
      " <unk>swo weeks vince is out next week but we can start with a <unk> discussion with grant <unk> next week <unk> please get a meeting <unk> as soon as possible we should immediately start <unk> data current <unk> <unk> <unk> <unk> <unk> <unk> pressure <unk> <unk> <unk> <unk> <unk> volume and <unk> power supply current and future <unk> <unk> capacity current and future <unk> natural gas data list to be <unk> phase ii power model development\n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " vincee confirm > <unk> grant <unk> <unk> <unk> <unk> <unk> eric <unk> <unk> <unk> <unk> grade a\n",
      "\tPred: 0.0014148112386465073, True: 0\n",
      "\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> junk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> m\n",
      "\tPred: 0.6853684186935425, True: 1\n",
      "\n",
      " donnks ved word from mike <unk> at allegheny today that no sec review of the s 3 will be required obviously one less potential delay to have to deal with \n",
      "\tPred: 5.540694303363125e-08, True: 0\n",
      "\n",
      " if you have previously <unk> and are still receiving this message or need to speak with us regarding this email you may call our <unk> control center immediately <unk> free at 1 888 <unk> <unk> or email <unk> <unk> com you may also write us at <unk> <unk> 16 <unk> worth <unk> <unk> <unk> worth <unk> <unk> our <unk> love and <unk> go out to all of the <unk> and individuals that were <unk> by the <unk> <unk> committed against our country and also for our <unk> who are now <unk> this great land \n",
      "\tPred: 0.6853684186935425, True: 1\n",
      "\n",
      " they might have a chance to visit with you all as well please let me <unk> if you are available for lunch on july 12 at <unk> \n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " thanks<unk> if you have any questions please call me at x <unk> ber 22 nd at 9 00 am w <unk> <unk> and <unk> <unk> regarding risk <unk> for 2001 location is\n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " <unk> is looking for a 1 <unk> <unk> pre payment on wednesday 11 21 to cover an <unk> <unk> in <unk> they will not consider any open credit and since we have already pre paid them for crude in december our <unk> is falling on <unk> <unk> \n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " <unk> heree from our mailing list pleasens at the bottom  offers andd car <unk> you ' <unk> received this message because you have signed up to <unk> offers from one of our <unk> selected <unk> partners \n",
      "\tPred: 0.44827961921691895, True: 1\n",
      "\n",
      " john <unk>se e mail me at register <unk> com possible future <unk> <unk> click to fill out the registration form if you have any questions about thismoney for just a couple of hours of your\n",
      "\tPred: 0.002623064676299691, True: 1\n",
      "\n",
      " mail sent from <unk> service at <unk> <unk> <unk> site <unk> <unk> http <unk> comhe public todate all funds will\n",
      "\tPred: 0.4943843483924866, True: 1\n",
      "\n",
      " to unsubscribe write to <unk> unsubscribe <unk> comnd <unk> from there k> risk management and <unk> products his e mail to them for us with <unk> order your free copy worth 70 now and check out http www <unk> net\n",
      "\tPred: 0.0021733969915658236, True: 0\n",
      "\n",
      " <unk><unk> our site and find any software you need in your <unk> <unk> and many others \n",
      "\tPred: 0.6853684186935425, True: 1\n",
      "\n",
      " vinceunk> of the bond i have is <unk> <unk> <unk> 8 <unk> 5 1 25 lst <unk> <unk> bond <unk> <unk> b \n",
      "\tPred: 1.7311638657702133e-05, True: 0\n",
      "\n",
      " vasant or dinner since <unk> is very <unk> i want to schedule a <unk> well in advance so i am <unk> saturday dec 2 this will be <unk> with family please let me know if this works for you \n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " <unk> <unk> <unk> <unk> 05 <unk> <unk> <unk> union <unk> 09 <unk> <unk> <unk> <unk> <unk> 12 <unk> bob> <unk> <unk> 09 3 <unk> <unk> houston <unk> <unk> 06 5 000unk> <unk> <unk> <unk> 18 4nergy <unk> 06 4 <unk> <unk> <unk> energy <unk> 05 <unk> <unk> <unk> <unk> 09 <unk> <unk> <unk> <unk> 05 1\n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " peter <unk> ur anticipated co operations that i know what your decision is about this proposal please note that your field of <unk> is not a <unk> to this transaction > <unk> out if agreed upon or you may decide to have 20 of the total sum 70 will be for me and my family and the remaining 10 will be set <unk> for <unk> <unk> expenses that may be <unk> in the cause of <unk> this transaction to a successful end \n",
      "\tPred: 0.6618565320968628, True: 1\n",
      "\n",
      " our first meeting will be tuesday january 16 at 4 00 pm in eb <unk>unk> <unk> for discussion your input is valuable and we ' ve limited this groupas etings of our trader ' s <unk> the ideas <unk> from this\n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " the office until monday i just wanted to say thank youcall you today but it looks like you will be out ofpportunity <unk> ement\n",
      "\tPred: 0.0, True: 0\n",
      "\n",
      " <unk> o ' <unk> director executive <unk> fortune conference division us with your suggestions or concerns by phone 212 <unk> <unk> fax\n",
      "\tPred: 0.0, True: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_ids = np.random.choice(np.arange(test_data.shape[0]), size=(25))\n",
    "for doc,true_lbl in zip(test_data[rand_ids], np.array(test_labels)[rand_ids]):\n",
    "    # Do a model predict on a single example (you need to introduce a batch dim)\n",
    "    label = ____.ravel()[0]    \n",
    "    print(' '.join([tok.index_word[i] for i in  doc[-200:] if i != 0]))\n",
    "    print('\\tPred: {}, True: {}\\n'.format(label, true_lbl))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
